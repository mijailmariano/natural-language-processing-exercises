{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Exercises: NLP Acquire/Web Scrapping``\n",
    "\n",
    "    30AUGUST2022\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook dependencies \n",
    "import os # for caching purposeses\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# regular expression import\n",
    "import re\n",
    "\n",
    "# JSON import\n",
    "import json\n",
    "\n",
    "# importing BeautifulSoup for parsing HTML/XTML\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# request module for connecting to APIs\n",
    "from requests import get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ``Exercise Number 1: Web Scrapping -- Codeup Blog Articles``\n",
    "\n",
    "**<u>``Prompt:``</u>**\n",
    "\n",
    "* Visit Codeup's Blog and record the urls for at least 5 distinct blog posts. \n",
    "\n",
    "* For each post, you should scrape at least the post's title and content.\n",
    "\n",
    "* Encapsulate your work in a function named get_blog_articles that will return a list of dictionaries:\n",
    "\n",
    "    - With each dictionary representing one article. The shape of each dictionary should look like this:\n",
    "\n",
    ">{\n",
    "    'title': 'the title of the article',\\\n",
    "    'content': 'the full text content of the article'\n",
    "}\n",
    "\n",
    "\n",
    "- Plus any additional properties you think might be helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://codeup.com/blog/\n"
     ]
    }
   ],
   "source": [
    "# let's connect to the Codeup url/domain\n",
    "\n",
    "domain = 'https://codeup.com'\n",
    "endpoint = '/blog/'\n",
    "\n",
    "# creating the url\n",
    "url = domain + endpoint\n",
    "\n",
    "# creating the response element/object (including headers)\n",
    "# note: some websites don't accept the pyhon-requests default user-agent\n",
    "headers = {'User-Agent': 'Codeup Data Science'} \n",
    "response = get(url, headers = headers)\n",
    "\n",
    "print(f'url: {url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the response object/type\n",
    "\n",
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's use the BeautifulSoup module to create an HTML object\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**``Beautiful Soup Methods and Properties``**\n",
    "\n",
    "* ``soup.title.string`` gets the page's title (the same text in the browser tab for a page, this is the title element\n",
    "\n",
    "* ``soup.prettify()`` is useful to print in case you want to see the HTML\n",
    "\n",
    "* ``soup.find_all(\"a\")`` find all the anchor tags, or whatever argument is specified.\n",
    "\n",
    "* ``soup.find(\"h1\")`` finds the first matching element\n",
    "\n",
    "* ``soup.get_text()`` gets the text from within a matching piece of soup/HTML\n",
    "\n",
    "* The ``soup.select()`` method takes in a CSS selector as a string and returns all matching elements. super useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://codeup.com/data-science/recession-proof-career/\">Is a Career in Tech Recession-Proof?</a>,\n",
       " <a href=\"https://codeup.com/codeup-news/codeup-x-comic-con/\">Codeup X Superhero Car Show &amp; Comic Con</a>,\n",
       " <a href=\"https://codeup.com/featured/series-part-3-web-development/\">What Jobs Can You Get After a Coding Bootcamp? Part 3: Web Development</a>,\n",
       " <a href=\"https://codeup.com/codeup-news/codeup-dallas-campus/\">Codeup’s New Dallas Campus</a>,\n",
       " <a href=\"https://codeup.com/codeup-news/codeup-tv-commercial/\">Codeup TV Commercial</a>,\n",
       " <a href=\"https://codeup.com/featured/what-jobs-can-you-get-after-a-coding-bootcamp-part-2-cloud-administration/\">What Jobs Can You Get After a Coding Bootcamp? Part 2: Cloud Administration</a>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in looking at the Codeup blog page, i notice the article titles at the 'h2 <a href = ' attribute level\n",
    "# i can use the select method to hit this attribute and return back all text tagged as such\n",
    "\n",
    "soup.select('h2 a[href]') # checks out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://codeup.com/data-science/recession-proof-career/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what if we just want a single title or link?\n",
    "\n",
    "url = soup.select('h2 a[href]')[0]['href'] # this is the link, what about the title?\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://codeup.com/data-science/recession-proof-career/\">Is a Career in Tech Recession-Proof?</a>,\n",
       " <a href=\"https://codeup.com/codeup-news/codeup-x-comic-con/\">Codeup X Superhero Car Show &amp; Comic Con</a>,\n",
       " <a href=\"https://codeup.com/featured/series-part-3-web-development/\">What Jobs Can You Get After a Coding Bootcamp? Part 3: Web Development</a>,\n",
       " <a href=\"https://codeup.com/codeup-news/codeup-dallas-campus/\">Codeup’s New Dallas Campus</a>,\n",
       " <a href=\"https://codeup.com/codeup-news/codeup-tv-commercial/\">Codeup TV Commercial</a>,\n",
       " <a href=\"https://codeup.com/featured/what-jobs-can-you-get-after-a-coding-bootcamp-part-2-cloud-administration/\">What Jobs Can You Get After a Coding Bootcamp? Part 2: Cloud Administration</a>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what if we want just the links to iterate through?\n",
    "\n",
    "urls = soup.select('h2 a[href]')[:]\n",
    "\n",
    "type(urls)\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aug 12, 2022'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting the published date\n",
    "\n",
    "published_date = soup.find('span', class_ = \"published\").text.strip() # checks out!\n",
    "published_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample title extraction code\n",
    "\n",
    "# container = []\n",
    "\n",
    "# # create the blog url\n",
    "# url = 'https://codeup.com/blog/'\n",
    "\n",
    "# # include the headers\n",
    "# headers = {'User-Agent': 'Codeup Data Science'} \n",
    "\n",
    "# #create the response object\n",
    "# response1 = get(url, headers = headers)\n",
    "\n",
    "# # first soup\n",
    "# soup1 = BeautifulSoup(response1.content, 'html.parser')\n",
    "\n",
    "# # hit the blog domain and retrieve article link\n",
    "# link_url = soup1.select('h2 a[href]')[counter][\"href\"]\n",
    "\n",
    "# response2 = get(link_url, headers = headers)\n",
    "\n",
    "# # new soup object\n",
    "# soup2 = BeautifulSoup(response2.content, 'html.parser')\n",
    "\n",
    "# soup2.find('h1', class_ = \"entry-title\").text # checks out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup X Superhero Car Show &amp; Comic Con</td>\n",
       "      <td>Aug 10, 2022</td>\n",
       "      <td>Codeup had a blast at the San Antonio Superher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is a Career in Tech Recession-Proof?</td>\n",
       "      <td>Aug 12, 2022</td>\n",
       "      <td>Given the current economic climate, many econo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What Jobs Can You Get After a Coding Bootcamp?...</td>\n",
       "      <td>Aug 2, 2022</td>\n",
       "      <td>If you’re considering a career in web developm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What Jobs Can You Get After a Coding Bootcamp?...</td>\n",
       "      <td>Jul 14, 2022</td>\n",
       "      <td>Have you been considering a career in Cloud Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Codeup TV Commercial</td>\n",
       "      <td>Jul 20, 2022</td>\n",
       "      <td>Codeup has officially made its TV debut! Our c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Codeup’s New Dallas Campus</td>\n",
       "      <td>Jul 25, 2022</td>\n",
       "      <td>Codeup’s Dallas campus has a new location! For...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       article_title  publish_date  \\\n",
       "0            Codeup X Superhero Car Show & Comic Con  Aug 10, 2022   \n",
       "1               Is a Career in Tech Recession-Proof?  Aug 12, 2022   \n",
       "2  What Jobs Can You Get After a Coding Bootcamp?...   Aug 2, 2022   \n",
       "3  What Jobs Can You Get After a Coding Bootcamp?...  Jul 14, 2022   \n",
       "4                               Codeup TV Commercial  Jul 20, 2022   \n",
       "5                         Codeup’s New Dallas Campus  Jul 25, 2022   \n",
       "\n",
       "                                            contents  \n",
       "0  Codeup had a blast at the San Antonio Superher...  \n",
       "1  Given the current economic climate, many econo...  \n",
       "2  If you’re considering a career in web developm...  \n",
       "3  Have you been considering a career in Cloud Ad...  \n",
       "4  Codeup has officially made its TV debut! Our c...  \n",
       "5  Codeup’s Dallas campus has a new location! For...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with the links accessible, i can hit the needed articles to extract more data\n",
    "\n",
    "container = []\n",
    "\n",
    "# let's extract all articles in the Codeup blog post website\n",
    "for num in range(len(urls)):\n",
    "\n",
    "    # extracting the article url from Codeup blog urls\n",
    "    article_url = urls[num]['href']\n",
    "\n",
    "    # creating the response object (Article Website)\n",
    "    response = get(article_url, headers = headers)\n",
    "\n",
    "    # create the soup object\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # extract the title\n",
    "    title = soup.find('h1', class_ = \"entry-title\").text\n",
    "    \n",
    "    # extract the publish date\n",
    "    published = soup.find('span', class_ = \"published\").text.strip()\n",
    "    \n",
    "    # extract article body\n",
    "    contents = soup.find('div', class_ = 'entry-content').text.strip()\n",
    "\n",
    "    # create dictionary that holds article contents\n",
    "    article_dict = { \n",
    "        \"article_title\": title,\n",
    "        \"publish_date\": published,\n",
    "        \"contents\": contents\n",
    "    }\n",
    "\n",
    "    # append article dictionary to the container list\n",
    "    container.append(article_dict)\n",
    "\n",
    "articles = pd.DataFrame(container).sort_values(\"publish_date\").reset_index(drop = True)\n",
    "articles\n",
    "\n",
    "# notes to self:\n",
    "# when creating a function that pulls information at scale, ensure the headers, tags, or required labeling of information is consistent and accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Have you been considering a career in Cloud Administration, but have no idea what your job title or potential salary could be? Continue reading below to find out!\\nIn this mini-series, we will take each of our programs here at Codeup: Data Science, Web Development, and Cloud Administration, and outline respectively potential job titles, as well as entry-level salaries.*\\xa0Let’s discuss Cloud Administration.\\nProgram Overview\\nAt Codeup, we offer a 15-week Cloud Administration program, which was derived from our previous two programs: Systems Engineering and Cyber Cloud. We combined the best of both and blended hands-on practical knowledge with skilled instructors to create the Cloud Administration program.\\nUpon completing this program, you’ll have the opportunity to take on two exams for certifications: Amazon Web Services (AWS) Cloud Practitioner and AWS Solutions Architect Associate.\\xa0\\nPotential Jobs\\nAccording to A Cloud Guru, with an AWS Certification you’ll be equipped with the knowledge and experience to secure a job as the following:\\n1. Cloud Architect\\nAs a Cloud Architect, you will double as an IT specialist responsible for your organization’s cloud infrastructure. This includes system monitoring, computing strategy, planning, building and deployment. An entry-level Cloud Architect can make an estimated $93,892 annually according to Glassdoor.\\xa0\\n2. Cloud Developer\\nA Cloud Developer’s main duties align with a software developer’s. The differentiating factor is a Cloud Developer operates virtually with cloud computing technology. This may include the design, analysis and maintenance of a company’s cloud infrastructure. An entry-level Cloud Developer can make an estimated $89,652 annually according to Glassdoor.\\xa0\\n3. Cloud Systems Administrator\\nA Cloud Systems Administrator can be expected to provide insight on cloud systems, specifically working with IT to provide assistance and resolve operational issues. An entry-level Cloud Systems Administrator can make an estimated $64,805 annually according to Glassdoor.\\nHonorable Mention\\nA few additional roles to consider with AWS Certification include:\\xa0\\n\\nCloud DevOps Engineer- Estimated Entry-Level Salary $88,563\\nCloud Security Engineer- Estimated Entry-Level Salary $85,111\\nCloud Data Architect- Estimated Entry-Level Salary $91,598\\nCloud Consultant- Estimated Entry-Level Salary $72,474\\n\\nInterested in the other parts of this mini-series? Check them out below!\\n\\nPart 1: Data Science\\nPart 3: Web Development (Coming Soon!)\\xa0\\n\\n*Disclaimer: All information presented in this article is by no means guaranteed by completing a Codeup program. Salaries and duties vary based on factors such as company, location, and experience. These salaries are estimates based on San Antonio, TX data, and these duties are general and may not be exact for every position.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract article/blog contents \n",
    "\n",
    "soup.find('div', class_ = 'entry-content').text.strip() # checks out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to scrape all Codeup blogs\n",
    "\n",
    "def scrape_codeup_blogs(url):\n",
    "\n",
    "    # providing url headers for referencing/access\n",
    "    headers = {'User-Agent': 'Codeup Data Science'}\n",
    "\n",
    "    # creating the response object to access to the url\n",
    "    response = get(url, headers = headers)\n",
    "\n",
    "    # creating the soup object\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # selecting/extracting all urls from the blog home page\n",
    "    urls = soup.select('h2 a[href]')[:]\n",
    "\n",
    "    # container list to store needed contents/attributes\n",
    "    container = []\n",
    "\n",
    "    # let's extract all articles in the Codeup blog post website\n",
    "    for num in range(len(urls)):\n",
    "\n",
    "        # extracting the article url from Codeup blog urls\n",
    "        article_url = urls[num]['href']\n",
    "\n",
    "        # creating the response object (Article Website)\n",
    "        response = get(article_url, headers = headers)\n",
    "\n",
    "        # create the soup object\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # extract the title\n",
    "        title = soup.find('h1', class_ = \"entry-title\").text\n",
    "        \n",
    "        # extract the publish date\n",
    "        published = soup.find('span', class_ = \"published\").text.strip()\n",
    "        \n",
    "        # extract article body\n",
    "        contents = soup.find('div', class_ = 'entry-content').text.strip()\n",
    "\n",
    "        # create dictionary that holds article contents\n",
    "        article_dict = { \n",
    "            \n",
    "            \"article_title\": title,\n",
    "            \"publish_date\": published,\n",
    "            \"contents\": contents\n",
    "        }\n",
    "\n",
    "        # append article dictionary to the container list\n",
    "        container.append(article_dict)\n",
    "\n",
    "    # create an articles/blogs dataframe\n",
    "    df = pd.DataFrame(container).sort_values(\"publish_date\").reset_index(drop = True)\n",
    "    \n",
    "    # print the shape\n",
    "    print(f'dataframe shape: {df.shape}')\n",
    "\n",
    "    # return articles/blogs in a Pandas Dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape: (6, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup X Superhero Car Show &amp; Comic Con</td>\n",
       "      <td>Aug 10, 2022</td>\n",
       "      <td>Codeup had a blast at the San Antonio Superher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is a Career in Tech Recession-Proof?</td>\n",
       "      <td>Aug 12, 2022</td>\n",
       "      <td>Given the current economic climate, many econo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What Jobs Can You Get After a Coding Bootcamp?...</td>\n",
       "      <td>Aug 2, 2022</td>\n",
       "      <td>If you’re considering a career in web developm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What Jobs Can You Get After a Coding Bootcamp?...</td>\n",
       "      <td>Jul 14, 2022</td>\n",
       "      <td>Have you been considering a career in Cloud Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Codeup TV Commercial</td>\n",
       "      <td>Jul 20, 2022</td>\n",
       "      <td>Codeup has officially made its TV debut! Our c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Codeup’s New Dallas Campus</td>\n",
       "      <td>Jul 25, 2022</td>\n",
       "      <td>Codeup’s Dallas campus has a new location! For...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       article_title  publish_date  \\\n",
       "0            Codeup X Superhero Car Show & Comic Con  Aug 10, 2022   \n",
       "1               Is a Career in Tech Recession-Proof?  Aug 12, 2022   \n",
       "2  What Jobs Can You Get After a Coding Bootcamp?...   Aug 2, 2022   \n",
       "3  What Jobs Can You Get After a Coding Bootcamp?...  Jul 14, 2022   \n",
       "4                               Codeup TV Commercial  Jul 20, 2022   \n",
       "5                         Codeup’s New Dallas Campus  Jul 25, 2022   \n",
       "\n",
       "                                            contents  \n",
       "0  Codeup had a blast at the San Antonio Superher...  \n",
       "1  Given the current economic climate, many econo...  \n",
       "2  If you’re considering a career in web developm...  \n",
       "3  Have you been considering a career in Cloud Ad...  \n",
       "4  Codeup has officially made its TV debut! Our c...  \n",
       "5  Codeup’s Dallas campus has a new location! For...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying out the function\n",
    "\n",
    "codeup_blogs = scrape_codeup_blogs('https://codeup.com/blog/')\n",
    "codeup_blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to scrape all Codeup blogs\n",
    "\n",
    "def get_blogs_dict(url):\n",
    "\n",
    "    # providing url headers for referencing/access\n",
    "    headers = {'User-Agent': 'Codeup Data Science'}\n",
    "\n",
    "    # creating the response object to access to the url\n",
    "    response = get(url, headers = headers)\n",
    "\n",
    "    # creating the soup object\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # selecting/extracting all urls from the blog home page\n",
    "    urls = soup.select('h2 a[href]')[:]\n",
    "\n",
    "    # container list to store needed contents/attributes\n",
    "    container = []\n",
    "\n",
    "    # let's extract all articles in the Codeup blog post website\n",
    "    for num in range(len(urls)):\n",
    "\n",
    "        # extracting the article url from Codeup blog urls\n",
    "        article_url = urls[num]['href']\n",
    "\n",
    "        # creating the response object (Article Website)\n",
    "        response = get(article_url, headers = headers)\n",
    "\n",
    "        # create the soup object\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # extract the title\n",
    "        title = soup.find('h1', class_ = \"entry-title\").text\n",
    "        \n",
    "        # extract the publish date\n",
    "        published = soup.find('span', class_ = \"published\").text.strip()\n",
    "        \n",
    "        # extract article body\n",
    "        contents = soup.find('div', class_ = 'entry-content').text.strip()\n",
    "\n",
    "        # create dictionary that holds article contents\n",
    "        article_dict = { \n",
    "            \"article_title\": title,\n",
    "            \"publish_date\": published,\n",
    "            \"contents\": contents\n",
    "        }\n",
    "\n",
    "        # append article dictionary to the container list\n",
    "        container.append(article_dict)\n",
    "\n",
    "    with open(\"filename\", 'w') as f:\n",
    "\n",
    "        json.dump(container, f)\n",
    "\n",
    "    # return articles/blogs in a Pandas Dataframe\n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to scrape all Codeup blogs\n",
    "\n",
    "def return_blogs_list(url):\n",
    "    \n",
    "    # providing url headers for referencing/access\n",
    "    headers = {'User-Agent': 'Codeup Data Science'}\n",
    "\n",
    "    # creating the response object to access to the url\n",
    "    response = get(url, headers = headers)\n",
    "\n",
    "    # creating the soup object\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # selecting/extracting all urls from the blog home page\n",
    "    urls = soup.select('h2 a[href]')[:]\n",
    "\n",
    "    # container list to store needed contents/attributes\n",
    "    container = []\n",
    "\n",
    "    # let's extract all articles in the Codeup blog post website\n",
    "    for num in range(len(urls)):\n",
    "\n",
    "        # extracting the article url from Codeup blog urls\n",
    "        article_url = urls[num]['href']\n",
    "\n",
    "        # creating the response object (Article Website)\n",
    "        response = get(article_url, headers = headers)\n",
    "\n",
    "        # create the soup object\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # extract the title\n",
    "        title = soup.find('h1', class_ = \"entry-title\").text\n",
    "\n",
    "        # extract the publish date\n",
    "        published = soup.find('span', class_ = \"published\").text.strip()\n",
    "\n",
    "        # extract article body\n",
    "        contents = soup.find('div', class_ = 'entry-content').text.strip()\n",
    "\n",
    "        # create dictionary that holds article contents\n",
    "        article_dict = { \n",
    "\n",
    "        \"article_title\": title,\n",
    "        \"publish_date\": published,\n",
    "        \"contents\": contents\n",
    "\n",
    "        }\n",
    "\n",
    "        # append article dictionary to the container list\n",
    "        container.append(article_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape: (6, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup X Superhero Car Show &amp; Comic Con</td>\n",
       "      <td>Aug 10, 2022</td>\n",
       "      <td>Codeup had a blast at the San Antonio Superher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is a Career in Tech Recession-Proof?</td>\n",
       "      <td>Aug 12, 2022</td>\n",
       "      <td>Given the current economic climate, many econo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What Jobs Can You Get After a Coding Bootcamp?...</td>\n",
       "      <td>Aug 2, 2022</td>\n",
       "      <td>If you’re considering a career in web developm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What Jobs Can You Get After a Coding Bootcamp?...</td>\n",
       "      <td>Jul 14, 2022</td>\n",
       "      <td>Have you been considering a career in Cloud Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Codeup TV Commercial</td>\n",
       "      <td>Jul 20, 2022</td>\n",
       "      <td>Codeup has officially made its TV debut! Our c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Codeup’s New Dallas Campus</td>\n",
       "      <td>Jul 25, 2022</td>\n",
       "      <td>Codeup’s Dallas campus has a new location! For...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       article_title  publish_date  \\\n",
       "0            Codeup X Superhero Car Show & Comic Con  Aug 10, 2022   \n",
       "1               Is a Career in Tech Recession-Proof?  Aug 12, 2022   \n",
       "2  What Jobs Can You Get After a Coding Bootcamp?...   Aug 2, 2022   \n",
       "3  What Jobs Can You Get After a Coding Bootcamp?...  Jul 14, 2022   \n",
       "4                               Codeup TV Commercial  Jul 20, 2022   \n",
       "5                         Codeup’s New Dallas Campus  Jul 25, 2022   \n",
       "\n",
       "                                            contents  \n",
       "0  Codeup had a blast at the San Antonio Superher...  \n",
       "1  Given the current economic climate, many econo...  \n",
       "2  If you’re considering a career in web developm...  \n",
       "3  Have you been considering a career in Cloud Ad...  \n",
       "4  Codeup has officially made its TV debut! Our c...  \n",
       "5  Codeup’s Dallas campus has a new location! For...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing out the Codeup web scrape function\n",
    "# if successful, it should return back the same/similar df to the one previously created\n",
    "\n",
    "codeup_blogs = scrape_codeup_blogs(\"https://codeup.com/blog/\")\n",
    "codeup_blogs # checks out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### ``Exercise Number 2: News Articles``\n",
    "\n",
    "We will now be scraping text data from inshorts, a website that provides a brief overview of many different topics.\n",
    "\n",
    "Write a function that scrapes the news articles for the following topics:\n",
    "\n",
    "* Business\n",
    "* Sports\n",
    "* Technology\n",
    "* Entertainment\n",
    "\n",
    "\n",
    "``The end product of this should be a function named get_news_articles that returns a list of dictionaries, where each dictionary has this shape:``\n",
    "\n",
    ">{\n",
    "'title': 'The article title',\\\n",
    "'content': 'The article content',\\\n",
    "'category': 'business' # for example\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check out the initial site\n",
    "\n",
    "url = 'https://inshorts.com/en/read/business'\n",
    "\n",
    "response = get(url)\n",
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what's in the object\n",
    "\n",
    "response # successful connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a beautifulsoup object and exploring the site further\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "type(soup) # object type checks out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"India's GDP grows at 13.5% in first quarter of FY23, fastest in a year\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what's in the read page of inshorts: looking at one title\n",
    "\n",
    "soup.find('span', itemprop = 'headline').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span itemprop=\"headline\">India's GDP grows at 13.5% in first quarter of FY23, fastest in a year</span>,\n",
       " <span itemprop=\"headline\">Snap to lay off 20% of staff, cancel several projects to cut costs</span>,\n",
       " <span itemprop=\"headline\">2 top executives at Snap quit hours after report about 20% layoffs emerges</span>,\n",
       " <span itemprop=\"headline\">Musk seeks to delay Twitter trial to Nov amid whistleblower's claims</span>,\n",
       " <span itemprop=\"headline\">Viral video shows Amazon parcels thrown out of train at station, Railways clarifies</span>,\n",
       " <span itemprop=\"headline\">Dell among firms conducting stay interviews to contain high attrition rates: Report</span>,\n",
       " <span itemprop=\"headline\">World's 3rd richest person Adani's wealth surged over 13 times in 2.5 years</span>,\n",
       " <span itemprop=\"headline\">Russia's Gazprom halts gas supply to Europe via major pipeline</span>,\n",
       " <span itemprop=\"headline\">Japan calls for $24 bn investment to boost battery competitiveness</span>,\n",
       " <span itemprop=\"headline\">Infosys divests entire stake in US-based Trifacta for $12 million</span>,\n",
       " <span itemprop=\"headline\">Netflix hires 2 top advertising executives from Snapchat-parent Snap Inc</span>,\n",
       " <span itemprop=\"headline\">SoftBank Corporate Officer Rajeev Misra steps down amid record loss</span>,\n",
       " <span itemprop=\"headline\">Axis Bank looking to acquire 10% stake in Go Digit: Report</span>,\n",
       " <span itemprop=\"headline\">Dennis Woodside appointed as President of Freshworks</span>,\n",
       " <span itemprop=\"headline\">Tata Motors completes buying of Marcopolo's stake for ₹99.96 crore</span>,\n",
       " <span itemprop=\"headline\">States, UTs to get chana at ₹8/kg discount for welfare schemes</span>,\n",
       " <span itemprop=\"headline\">IMF to make formal announcement on SL bailout package on Thurs: Report</span>,\n",
       " <span itemprop=\"headline\">Pak at challenging economic juncture: IMF while approving bailout</span>,\n",
       " <span itemprop=\"headline\">NPCI receives RBI nod to acquire 10% stake in ONDC</span>,\n",
       " <span itemprop=\"headline\">India's B2B general trade to reach $1.2 trillion by 2030: Redseer</span>,\n",
       " <span itemprop=\"headline\">Tata Steel to invest in hydrogen-based steel production in Netherlands</span>,\n",
       " <span itemprop=\"headline\">Air India retains Captain RS Sandhu as Chief of Operations</span>,\n",
       " <span itemprop=\"headline\">Reliance Industries acquires soft drink brand Campa: Report</span>,\n",
       " <span itemprop=\"headline\">NSDL likely to shortlist 7 investment banks for 2023 IPO: Reports</span>,\n",
       " <span itemprop=\"headline\">FPIs turn net buyers of Indian shares in a month 1st time since Sept 2021</span>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok, but can we get all the tiles? using the find_all() method\n",
    "\n",
    "soup.find_all('span', itemprop = 'headline') # checks out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notes to self: use the find_all() method and iterate through the needed attributes/tags\n",
    "# ensure that the total numner of titles matches the total number of authors, publish date, content, etc. \n",
    "# 25 articles on the Business page\n",
    "\n",
    "len(soup.find_all('span', itemprop = 'headline'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting the author \n",
    "# reminder that class is a reserved python word, so must use 'class_' to specify html tag\n",
    "# here! i see that there can be multiple authors on one single blog; makes sense!\n",
    "\n",
    "len(soup.find_all('span', class_ = 'author'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what about content blurbs/paragraphas\n",
    "# checks out! 25 articles and 25 titles\n",
    "\n",
    "len(soup.find_all('div', itemprop = 'articleBody'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 25)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# understanding the contents object\n",
    "\n",
    "contents = soup.find_all('div', itemprop = 'articleBody')\n",
    "range(len(contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the news article function\n",
    "\n",
    "def get_news_articles(website_url):\n",
    "\n",
    "    # create the unique response object\n",
    "    response = get(website_url)\n",
    "\n",
    "    # create the soup object\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # creating a list of titles/headlines to iterate throug\n",
    "    titles = soup.find_all('span', itemprop = 'headline')\n",
    "\n",
    "    dates = soup.find_all('span', class_ = 'date')\n",
    "\n",
    "    sources = soup.find_all('a', class_ = 'source')\n",
    "\n",
    "    authors = soup.find_all('span', class_ = 'author')\n",
    "\n",
    "    contents = soup.find_all('div', itemprop = 'articleBody')\n",
    "\n",
    "    # creating a container list to hold article contents in\n",
    "    container = []\n",
    "\n",
    "    # iterate through the total number of headlines on website\n",
    "    for num in range(len(titles)):\n",
    "        \n",
    "        published = dates[num].text\n",
    "\n",
    "        title = titles[num].text\n",
    "\n",
    "        author = authors[num].text\n",
    "\n",
    "        content = contents[num].text\n",
    "        \n",
    "        '''IF Statement to handle instances where there is not a source.\n",
    "        This code can probably be written more efficiently and/or across all collected attributes.'''\n",
    "        \n",
    "        if num in range(len(sources)):\n",
    "\n",
    "                source = sources[num].text\n",
    "\n",
    "        else: \n",
    "\n",
    "            source = None\n",
    "            \n",
    "        # creating a dictionary to save the articles contents\n",
    "        article_dict = { \n",
    "            \n",
    "            'publish_date': published, \n",
    "            'source': source, \n",
    "            'title': title,\n",
    "            'authors': author,\n",
    "            'content': content\n",
    "        }\n",
    "\n",
    "        # append to container list\n",
    "        container.append(article_dict)\n",
    "    \n",
    "    # creating a dataframe from all scrapped articles\n",
    "    article_df = pd.DataFrame(container)\n",
    "\n",
    "    # printing the dataframe shape\n",
    "    print(f'dataframe shape: {article_df.shape}')\n",
    "\n",
    "    return article_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape: (25, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>India's GDP grows at 13.5% in first quarter of...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>India's GDP grew at 13.5% in the first quarter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Snap to lay off 20% of staff, cancel several p...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>Snap said on Wednesday it will lay off 20% of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>2 top executives at Snap quit hours after repo...</td>\n",
       "      <td>Ananya Goyal</td>\n",
       "      <td>Two senior advertising executives at Snap quit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Musk seeks to delay Twitter trial to Nov amid ...</td>\n",
       "      <td>Ananya Goyal</td>\n",
       "      <td>Tesla CEO Elon Musk is seeking to delay the tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31 Aug</td>\n",
       "      <td>News18</td>\n",
       "      <td>Viral video shows Amazon parcels thrown out of...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>A video from Guwahati railway station has gone...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publish_date   source                                              title  \\\n",
       "0       31 Aug  Twitter  India's GDP grows at 13.5% in first quarter of...   \n",
       "1       31 Aug  Reuters  Snap to lay off 20% of staff, cancel several p...   \n",
       "2       31 Aug  Reuters  2 top executives at Snap quit hours after repo...   \n",
       "3       31 Aug  Reuters  Musk seeks to delay Twitter trial to Nov amid ...   \n",
       "4       31 Aug   News18  Viral video shows Amazon parcels thrown out of...   \n",
       "\n",
       "          authors                                            content  \n",
       "0    Anmol Sharma  India's GDP grew at 13.5% in the first quarter...  \n",
       "1    Anmol Sharma  Snap said on Wednesday it will lay off 20% of ...  \n",
       "2    Ananya Goyal  Two senior advertising executives at Snap quit...  \n",
       "3    Ananya Goyal  Tesla CEO Elon Musk is seeking to delay the tr...  \n",
       "4  Ridham Gambhir  A video from Guwahati railway station has gone...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing out the function\n",
    "\n",
    "inshort_busns = get_news_articles('https://inshorts.com/en/read/business')\n",
    "inshort_busns.head() # where there are 5 unique authors on the inshort business site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape: (25, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['BCCI', 'ICC', 'Times Now', 'Hindustan Times', 'The Independent',\n",
       "       'CricTracker', 'ANI', 'Sportskeeda'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the function on the 'Sports' section\n",
    "\n",
    "inshort_sports = get_news_articles('https://inshorts.com/en/read/sports')\n",
    "inshort_sports[\"source\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape: (25, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Snap to lay off 20% of staff, cancel several p...</td>\n",
       "      <td>Ananya Goyal</td>\n",
       "      <td>Snap said on Wednesday it will lay off 20% of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Musk cites whistleblower's claims in new notic...</td>\n",
       "      <td>Ananya Goyal</td>\n",
       "      <td>Tesla CEO Elon Musk's legal team has filed ano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>American man sues Tesla over car suddenly stop...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>Jose Alvarez Toledo, a Tesla Model 3 owner fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>2 top executives at Snap quit hours after repo...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>Two senior advertising executives at Snap quit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Facebook's Gaming app to be shut down in Octob...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>Facebook’s Gaming app for iOS and Android is s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publish_date   source                                              title  \\\n",
       "0       31 Aug  Reuters  Snap to lay off 20% of staff, cancel several p...   \n",
       "1       30 Aug  Reuters  Musk cites whistleblower's claims in new notic...   \n",
       "2       30 Aug  Reuters  American man sues Tesla over car suddenly stop...   \n",
       "3       31 Aug  Reuters  2 top executives at Snap quit hours after repo...   \n",
       "4       31 Aug  Reuters  Facebook's Gaming app to be shut down in Octob...   \n",
       "\n",
       "          authors                                            content  \n",
       "0    Ananya Goyal  Snap said on Wednesday it will lay off 20% of ...  \n",
       "1    Ananya Goyal  Tesla CEO Elon Musk's legal team has filed ano...  \n",
       "2  Ridham Gambhir  Jose Alvarez Toledo, a Tesla Model 3 owner fro...  \n",
       "3  Ridham Gambhir  Two senior advertising executives at Snap quit...  \n",
       "4    Anmol Sharma  Facebook’s Gaming app for iOS and Android is s...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the function on the 'Technology' section\n",
    "\n",
    "inshort_tech = get_news_articles('https://inshorts.com/en/read/technology')\n",
    "inshort_tech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape: (25, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>Shah Rukh Khan celebrates Ganesh Chaturthi, sh...</td>\n",
       "      <td>Daisy Mowke</td>\n",
       "      <td>Actor Shah Rukh Khan took to social media to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Hindustan Times</td>\n",
       "      <td>Jacqueline knew about Sukesh's criminal past &amp;...</td>\n",
       "      <td>Daisy Mowke</td>\n",
       "      <td>The ED's chargesheet filed against Jacqueline ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31 Aug</td>\n",
       "      <td>ANI</td>\n",
       "      <td>Jacqueline Fernandez summoned by Delhi court i...</td>\n",
       "      <td>Daisy Mowke</td>\n",
       "      <td>Delhi's Patiala House Court has summoned actre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31 Aug</td>\n",
       "      <td>The Associated Press</td>\n",
       "      <td>Aamir Khan to not charge fee for Laal Singh Ch...</td>\n",
       "      <td>Daisy Mowke</td>\n",
       "      <td>Aamir Khan's 'Laal Singh Chaddha' has not been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Bollywood Hungama</td>\n",
       "      <td>S Korea may hold survey on BTS members' mandat...</td>\n",
       "      <td>Apaar Sharma</td>\n",
       "      <td>South Korea is considering a survey to determi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publish_date                source  \\\n",
       "0       31 Aug            Instagram    \n",
       "1       31 Aug       Hindustan Times   \n",
       "2       31 Aug                   ANI   \n",
       "3       31 Aug  The Associated Press   \n",
       "4       31 Aug     Bollywood Hungama   \n",
       "\n",
       "                                               title       authors  \\\n",
       "0  Shah Rukh Khan celebrates Ganesh Chaturthi, sh...   Daisy Mowke   \n",
       "1  Jacqueline knew about Sukesh's criminal past &...   Daisy Mowke   \n",
       "2  Jacqueline Fernandez summoned by Delhi court i...   Daisy Mowke   \n",
       "3  Aamir Khan to not charge fee for Laal Singh Ch...   Daisy Mowke   \n",
       "4  S Korea may hold survey on BTS members' mandat...  Apaar Sharma   \n",
       "\n",
       "                                             content  \n",
       "0  Actor Shah Rukh Khan took to social media to s...  \n",
       "1  The ED's chargesheet filed against Jacqueline ...  \n",
       "2  Delhi's Patiala House Court has summoned actre...  \n",
       "3  Aamir Khan's 'Laal Singh Chaddha' has not been...  \n",
       "4  South Korea is considering a survey to determi...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the function on the 'Entertainment' section\n",
    "\n",
    "inshort_ent = get_news_articles('https://inshorts.com/en/read/entertainment')\n",
    "inshort_ent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### ``Exercise Number 3: Caching the Data``\n",
    "\n",
    "**<u>Notes:</u>**\n",
    "\n",
    "* Write your code such that the acquired data is saved locally in some form or fashion. Your functions that retrieve the data should prefer to read the local data instead of having to make all the requests everytime the function is called. \n",
    "* Include a boolean flag in the functions to allow the data to be acquired \"fresh\" from the actual sources (re-writing your local cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first cache the Codeup and Inshorts article dataframes\n",
    "\n",
    "codeup_blogs.to_csv(\"/Users/mijailmariano/codeup-data-science/natural-language-processing-exercises/codeup_blogs.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to first: check if the Codeup Blogs dataset exists, if not: scrape the web for it\n",
    "\n",
    "def get_codeup_blogs():\n",
    "\n",
    "    # creating the operating system filename for referencing\n",
    "    filename = \"codeup_blogs.csv\"\n",
    "    \n",
    "    # check to see if the file path exists\n",
    "    if os.path.isfile(filename):\n",
    "        \n",
    "        # if found, read the csv as a Pandas Dataframe\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        # let's print the shape\n",
    "        print(f'df shape: {df.shape}')\n",
    "\n",
    "        # return the blogs dataset\n",
    "        return df\n",
    "    \n",
    "    # if not cached, then retrieve the data from Codeup's blog site\n",
    "    else:\n",
    "\n",
    "        # set the Codeup Blogs url\n",
    "        url = \"https://codeup.com/blog/\"\n",
    "\n",
    "        # providing url headers for referencing/web access\n",
    "        headers = {'User-Agent': 'Codeup Data Science'}\n",
    "\n",
    "        # creating the response object to access to the url\n",
    "        response = get(url, headers = headers)\n",
    "\n",
    "        # creating the Codeup Blogs soup object\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # selecting/extracting all urls from the blog home page\n",
    "        urls = soup.select('h2 a[href]')[:]\n",
    "\n",
    "        # container list to store needed contents/attributes\n",
    "        container = []\n",
    "\n",
    "        # let's extract all articles in the Codeup blog post website\n",
    "        for num in range(len(urls)):\n",
    "\n",
    "            # extracting the article url from Codeup blog urls\n",
    "            article_url = urls[num]['href']\n",
    "\n",
    "            # creating the response object (Article Website)\n",
    "            response = get(article_url, headers = headers)\n",
    "\n",
    "            # create the soup object\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "            # extract the title\n",
    "            title = soup.find('h1', class_ = \"entry-title\").text\n",
    "            \n",
    "            # extract the publish date\n",
    "            published = soup.find('span', class_ = \"published\").text.strip()\n",
    "            \n",
    "            # extract article body\n",
    "            contents = soup.find('div', class_ = 'entry-content').text.strip()\n",
    "\n",
    "            # create dictionary that holds article contents\n",
    "            article_dict = { \n",
    "                \"article_title\": title,\n",
    "                \"publish_date\": published,\n",
    "                \"contents\": contents\n",
    "            }\n",
    "\n",
    "            # append article dictionary to the container list\n",
    "            container.append(article_dict)\n",
    "\n",
    "        # create an articles/blogs dataframe\n",
    "        df = pd.DataFrame(container).sort_values(\"publish_date\").reset_index(drop = True)\n",
    "        \n",
    "        # creating a .csv file in local directory for future referencing\n",
    "        df.to_csv(\"codeup_blogs.csv\", index = False)\n",
    "\n",
    "        # print the shape\n",
    "        print(f'dataframe shape: {df.shape}')\n",
    "\n",
    "        # return articles/blogs in a Pandas Dataframe\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (22, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup X Superhero Car Show &amp; Comic Con</td>\n",
       "      <td>Aug 10, 2022</td>\n",
       "      <td>Codeup had a blast at the San Antonio Superher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is a Career in Tech Recession-Proof?</td>\n",
       "      <td>Aug 12, 2022</td>\n",
       "      <td>Given the current economic climate, many econo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is a Career in Tech Recession-Proof?</td>\n",
       "      <td>Aug 12, 2022</td>\n",
       "      <td>Given the current economic climate, many econo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What Jobs Can You Get After a Coding Bootcamp?...</td>\n",
       "      <td>Aug 2, 2022</td>\n",
       "      <td>If you’re considering a career in web developm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What Jobs Can You Get After a Coding Bootcamp?...</td>\n",
       "      <td>Aug 2, 2022</td>\n",
       "      <td>If you’re considering a career in web developm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       article_title  publish_date  \\\n",
       "0            Codeup X Superhero Car Show & Comic Con  Aug 10, 2022   \n",
       "1               Is a Career in Tech Recession-Proof?  Aug 12, 2022   \n",
       "2               Is a Career in Tech Recession-Proof?  Aug 12, 2022   \n",
       "3  What Jobs Can You Get After a Coding Bootcamp?...   Aug 2, 2022   \n",
       "4  What Jobs Can You Get After a Coding Bootcamp?...   Aug 2, 2022   \n",
       "\n",
       "                                            contents  \n",
       "0  Codeup had a blast at the San Antonio Superher...  \n",
       "1  Given the current economic climate, many econo...  \n",
       "2  Given the current economic climate, many econo...  \n",
       "3  If you’re considering a career in web developm...  \n",
       "4  If you’re considering a career in web developm...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's test the get codeup blogs function\n",
    "# can add to acquire file\n",
    "\n",
    "df = get_codeup_blogs()\n",
    "df.head() # checks out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'entertainment'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try extracting the genre name from the url with regex\n",
    "\n",
    "re.findall(r'\\w+\\/?$', 'https://inshorts.com/en/read/entertainment')[0] # checks out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'entertainment'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# does it find the regex as a variable?\n",
    "\n",
    "url = 'https://inshorts.com/en/read/entertainment'\n",
    "\n",
    "re.findall(r'\\w+\\/?$', 'https://inshorts.com/en/read/entertainment')[0] # checks out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the news article function\n",
    "\n",
    "def get_news_articles(website_url):\n",
    "\n",
    "    # create the unique response object\n",
    "    response = get(website_url)\n",
    "\n",
    "    # creating a topic/genre object\n",
    "    genre = re.findall(r'\\w+\\/?$', website_url)[0]\n",
    "\n",
    "    # create the soup object\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # creating a list of titles/headlines to iterate throug\n",
    "    titles = soup.find_all('span', itemprop = 'headline')\n",
    "\n",
    "    dates = soup.find_all('span', class_ = 'date')\n",
    "\n",
    "    sources = soup.find_all('a', class_ = 'source')\n",
    "\n",
    "    authors = soup.find_all('span', class_ = 'author')\n",
    "\n",
    "    contents = soup.find_all('div', itemprop = 'articleBody')\n",
    "\n",
    "    # creating a container list to hold article contents in\n",
    "    container = []\n",
    "\n",
    "    # iterate through the total number of headlines on website\n",
    "    for num in range(len(titles)):\n",
    "        \n",
    "        published = dates[num].text\n",
    "\n",
    "        title = titles[num].text\n",
    "\n",
    "        author = authors[num].text\n",
    "\n",
    "        content = contents[num].text\n",
    "        \n",
    "        '''IF Statement to handle instances where there is not a source.\n",
    "        This code can probably be written more efficiently and/or across all collected attributes.'''\n",
    "        \n",
    "        if num in range(len(sources)):\n",
    "\n",
    "                source = sources[num].text\n",
    "\n",
    "        else: \n",
    "\n",
    "            source = None\n",
    "            \n",
    "        # creating a dictionary to save the articles contents\n",
    "        article_dict = { \n",
    "            \n",
    "            'genre': genre,\n",
    "            'publish_date': published, \n",
    "            'source': source, \n",
    "            'title': title,\n",
    "            'authors': author,\n",
    "            'content': content\n",
    "        }\n",
    "\n",
    "        # append to container list\n",
    "        container.append(article_dict)\n",
    "    \n",
    "    # creating a dataframe from all scrapped articles\n",
    "    article_df = pd.DataFrame(container)\n",
    "\n",
    "    # printing the dataframe shape\n",
    "    print(f'dataframe shape: {article_df.shape}')\n",
    "\n",
    "    return article_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the news article function\n",
    "\n",
    "def get_news_articles(website_url):\n",
    "\n",
    "    # create the unique response object\n",
    "    response = get(website_url)\n",
    "\n",
    "    # creating a topic/genre object\n",
    "    genre = re.findall(r'\\w+\\/?$', website_url)[0]\n",
    "\n",
    "    # create the soup object\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # creating a list of titles/headlines to iterate throug\n",
    "    titles = soup.find_all('span', itemprop = 'headline')\n",
    "\n",
    "    dates = soup.find_all('span', class_ = 'date')\n",
    "\n",
    "    sources = soup.find_all('a', class_ = 'source')\n",
    "\n",
    "    authors = soup.find_all('span', class_ = 'author')\n",
    "\n",
    "    contents = soup.find_all('div', itemprop = 'articleBody')\n",
    "\n",
    "    # creating a container list to hold article contents in\n",
    "    container = []\n",
    "\n",
    "    # iterate through the total number of headlines on website\n",
    "    for num in range(len(titles)):\n",
    "        \n",
    "        published = dates[num].text\n",
    "\n",
    "        title = titles[num].text\n",
    "\n",
    "        author = authors[num].text\n",
    "\n",
    "        content = contents[num].text\n",
    "        \n",
    "        '''IF Statement to handle instances where there is not a source.\n",
    "        This code can probably be written more efficiently and/or across all collected attributes.'''\n",
    "        \n",
    "        if num in range(len(sources)):\n",
    "\n",
    "                source = sources[num].text\n",
    "\n",
    "        else: \n",
    "\n",
    "            source = None\n",
    "            \n",
    "        # creating a dictionary to save the articles contents\n",
    "        article_dict = { \n",
    "            \n",
    "            'genre': genre,\n",
    "            'publish_date': published, \n",
    "            'source': source, \n",
    "            'title': title,\n",
    "            'authors': author,\n",
    "            'content': content\n",
    "        }\n",
    "\n",
    "        # append to container list\n",
    "        container.append(article_dict)\n",
    "    \n",
    "    # creating a dataframe from all scrapped articles\n",
    "    article_df = pd.DataFrame(container)\n",
    "\n",
    "    # printing the dataframe shape\n",
    "    print(f'dataframe shape: {article_df.shape}')\n",
    "\n",
    "    return article_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape: (25, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>Shah Rukh Khan celebrates Ganesh Chaturthi, sh...</td>\n",
       "      <td>Daisy Mowke</td>\n",
       "      <td>Actor Shah Rukh Khan took to social media to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Hindustan Times</td>\n",
       "      <td>Jacqueline knew about Sukesh's criminal past &amp;...</td>\n",
       "      <td>Daisy Mowke</td>\n",
       "      <td>The ED's chargesheet filed against Jacqueline ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>ANI</td>\n",
       "      <td>Jacqueline Fernandez summoned by Delhi court i...</td>\n",
       "      <td>Daisy Mowke</td>\n",
       "      <td>Delhi's Patiala House Court has summoned actre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>The Associated Press</td>\n",
       "      <td>Aamir Khan to not charge fee for Laal Singh Ch...</td>\n",
       "      <td>Daisy Mowke</td>\n",
       "      <td>Aamir Khan's 'Laal Singh Chaddha' has not been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Bollywood Hungama</td>\n",
       "      <td>S Korea may hold survey on BTS members' mandat...</td>\n",
       "      <td>Apaar Sharma</td>\n",
       "      <td>South Korea is considering a survey to determi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           genre publish_date                source  \\\n",
       "0  entertainment       31 Aug            Instagram    \n",
       "1  entertainment       31 Aug       Hindustan Times   \n",
       "2  entertainment       31 Aug                   ANI   \n",
       "3  entertainment       31 Aug  The Associated Press   \n",
       "4  entertainment       31 Aug     Bollywood Hungama   \n",
       "\n",
       "                                               title       authors  \\\n",
       "0  Shah Rukh Khan celebrates Ganesh Chaturthi, sh...   Daisy Mowke   \n",
       "1  Jacqueline knew about Sukesh's criminal past &...   Daisy Mowke   \n",
       "2  Jacqueline Fernandez summoned by Delhi court i...   Daisy Mowke   \n",
       "3  Aamir Khan to not charge fee for Laal Singh Ch...   Daisy Mowke   \n",
       "4  S Korea may hold survey on BTS members' mandat...  Apaar Sharma   \n",
       "\n",
       "                                             content  \n",
       "0  Actor Shah Rukh Khan took to social media to s...  \n",
       "1  The ED's chargesheet filed against Jacqueline ...  \n",
       "2  Delhi's Patiala House Court has summoned actre...  \n",
       "3  Aamir Khan's 'Laal Singh Chaddha' has not been...  \n",
       "4  South Korea is considering a survey to determi...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's test this function\n",
    "\n",
    "inshort_ent = get_news_articles('https://inshorts.com/en/read/entertainment')\n",
    "inshort_ent.head() # checks out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape: (25, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>BCCI</td>\n",
       "      <td>India beat Hong Kong to reach Asia Cup Super 4...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>India beat Hong Kong by 40 runs to qualify for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>ICC</td>\n",
       "      <td>Suryakumar Yadav smashes most sixes ever by an...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>Suryakumar Yadav on Wednesday broke the record...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>ICC</td>\n",
       "      <td>Hardik Pandya achieves his highest-ever spot i...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>Following his match-winning performance agains...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>ICC</td>\n",
       "      <td>India announce their playing XI for match agai...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>Hong Kong captain Nizakat Khan won the toss an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Times Now</td>\n",
       "      <td>Indian fan receives death threats for wearing ...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>Indian fan, who was seen wearing a Pakistan je...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    genre publish_date     source  \\\n",
       "0  sports       31 Aug       BCCI   \n",
       "1  sports       31 Aug        ICC   \n",
       "2  sports       31 Aug        ICC   \n",
       "3  sports       31 Aug        ICC   \n",
       "4  sports       31 Aug  Times Now   \n",
       "\n",
       "                                               title       authors  \\\n",
       "0  India beat Hong Kong to reach Asia Cup Super 4...  Anmol Sharma   \n",
       "1  Suryakumar Yadav smashes most sixes ever by an...  Anmol Sharma   \n",
       "2  Hardik Pandya achieves his highest-ever spot i...  Anmol Sharma   \n",
       "3  India announce their playing XI for match agai...  Anmol Sharma   \n",
       "4  Indian fan receives death threats for wearing ...  Anmol Sharma   \n",
       "\n",
       "                                             content  \n",
       "0  India beat Hong Kong by 40 runs to qualify for...  \n",
       "1  Suryakumar Yadav on Wednesday broke the record...  \n",
       "2  Following his match-winning performance agains...  \n",
       "3  Hong Kong captain Nizakat Khan won the toss an...  \n",
       "4  Indian fan, who was seen wearing a Pakistan je...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying another website\n",
    "\n",
    "inshort_sports = get_news_articles('https://inshorts.com/en/read/sports')\n",
    "inshort_sports.head() # checks out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape: (25, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>India's GDP grows at 13.5% in first quarter of...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>India's GDP grew at 13.5% in the first quarter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Snap to lay off 20% of staff, cancel several p...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>Snap said on Wednesday it will lay off 20% of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>2 top executives at Snap quit hours after repo...</td>\n",
       "      <td>Ananya Goyal</td>\n",
       "      <td>Two senior advertising executives at Snap quit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Musk seeks to delay Twitter trial to Nov amid ...</td>\n",
       "      <td>Ananya Goyal</td>\n",
       "      <td>Tesla CEO Elon Musk is seeking to delay the tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>News18</td>\n",
       "      <td>Viral video shows Amazon parcels thrown out of...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>A video from Guwahati railway station has gone...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      genre publish_date   source  \\\n",
       "0  business       31 Aug  Twitter   \n",
       "1  business       31 Aug  Reuters   \n",
       "2  business       31 Aug  Reuters   \n",
       "3  business       31 Aug  Reuters   \n",
       "4  business       31 Aug   News18   \n",
       "\n",
       "                                               title         authors  \\\n",
       "0  India's GDP grows at 13.5% in first quarter of...    Anmol Sharma   \n",
       "1  Snap to lay off 20% of staff, cancel several p...    Anmol Sharma   \n",
       "2  2 top executives at Snap quit hours after repo...    Ananya Goyal   \n",
       "3  Musk seeks to delay Twitter trial to Nov amid ...    Ananya Goyal   \n",
       "4  Viral video shows Amazon parcels thrown out of...  Ridham Gambhir   \n",
       "\n",
       "                                             content  \n",
       "0  India's GDP grew at 13.5% in the first quarter...  \n",
       "1  Snap said on Wednesday it will lay off 20% of ...  \n",
       "2  Two senior advertising executives at Snap quit...  \n",
       "3  Tesla CEO Elon Musk is seeking to delay the tr...  \n",
       "4  A video from Guwahati railway station has gone...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entertainment\n",
    "\n",
    "inshort_bus = get_news_articles('https://inshorts.com/en/read/business')\n",
    "inshort_bus.head() # checks out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape: (25, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>technology</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Snap to lay off 20% of staff, cancel several p...</td>\n",
       "      <td>Ananya Goyal</td>\n",
       "      <td>Snap said on Wednesday it will lay off 20% of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>technology</td>\n",
       "      <td>30 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Musk cites whistleblower's claims in new notic...</td>\n",
       "      <td>Ananya Goyal</td>\n",
       "      <td>Tesla CEO Elon Musk's legal team has filed ano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>technology</td>\n",
       "      <td>30 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>American man sues Tesla over car suddenly stop...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>Jose Alvarez Toledo, a Tesla Model 3 owner fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>technology</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>2 top executives at Snap quit hours after repo...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>Two senior advertising executives at Snap quit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>technology</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Facebook's Gaming app to be shut down in Octob...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>Facebook’s Gaming app for iOS and Android is s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        genre publish_date   source  \\\n",
       "0  technology       31 Aug  Reuters   \n",
       "1  technology       30 Aug  Reuters   \n",
       "2  technology       30 Aug  Reuters   \n",
       "3  technology       31 Aug  Reuters   \n",
       "4  technology       31 Aug  Reuters   \n",
       "\n",
       "                                               title         authors  \\\n",
       "0  Snap to lay off 20% of staff, cancel several p...    Ananya Goyal   \n",
       "1  Musk cites whistleblower's claims in new notic...    Ananya Goyal   \n",
       "2  American man sues Tesla over car suddenly stop...  Ridham Gambhir   \n",
       "3  2 top executives at Snap quit hours after repo...  Ridham Gambhir   \n",
       "4  Facebook's Gaming app to be shut down in Octob...    Anmol Sharma   \n",
       "\n",
       "                                             content  \n",
       "0  Snap said on Wednesday it will lay off 20% of ...  \n",
       "1  Tesla CEO Elon Musk's legal team has filed ano...  \n",
       "2  Jose Alvarez Toledo, a Tesla Model 3 owner fro...  \n",
       "3  Two senior advertising executives at Snap quit...  \n",
       "4  Facebook’s Gaming app for iOS and Android is s...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# technology\n",
    "\n",
    "inshort_tech = get_news_articles('https://inshorts.com/en/read/technology')\n",
    "inshort_tech.head() # checks out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>India's GDP grows at 13.5% in first quarter of...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>India's GDP grew at 13.5% in the first quarter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Snap to lay off 20% of staff, cancel several p...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>Snap said on Wednesday it will lay off 20% of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>2 top executives at Snap quit hours after repo...</td>\n",
       "      <td>Ananya Goyal</td>\n",
       "      <td>Two senior advertising executives at Snap quit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Musk seeks to delay Twitter trial to Nov amid ...</td>\n",
       "      <td>Ananya Goyal</td>\n",
       "      <td>Tesla CEO Elon Musk is seeking to delay the tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>News18</td>\n",
       "      <td>Viral video shows Amazon parcels thrown out of...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>A video from Guwahati railway station has gone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>sports</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Sportskeeda</td>\n",
       "      <td>India faced a 'lot of difficulty' when they la...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>Ex-Team India opener Wasim Jaffer said Team In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>sports</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Times Now</td>\n",
       "      <td>Pant can get into this side if Rahul doesn't f...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>Former India cricketer Saba Karim has said wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>sports</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Hindustan Times</td>\n",
       "      <td>I can't believe his place is under threat: Sty...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>During a discussion ahead of India's match aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>sports</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>CricTracker</td>\n",
       "      <td>Team India can tackle our bowlers, Pak can't: ...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>Former Afghanistan captain Asghar Afghan said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>sports</td>\n",
       "      <td>31 Aug</td>\n",
       "      <td>Sportskeeda</td>\n",
       "      <td>Kohli will score his 71st century vs Hong Kong...</td>\n",
       "      <td>Ankur Taliyan</td>\n",
       "      <td>Sri Lanka spinner Maheesh Theekshana, during a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       genre publish_date           source  \\\n",
       "0   business       31 Aug          Twitter   \n",
       "1   business       31 Aug          Reuters   \n",
       "2   business       31 Aug          Reuters   \n",
       "3   business       31 Aug          Reuters   \n",
       "4   business       31 Aug           News18   \n",
       "..       ...          ...              ...   \n",
       "95    sports       31 Aug      Sportskeeda   \n",
       "96    sports       31 Aug        Times Now   \n",
       "97    sports       31 Aug  Hindustan Times   \n",
       "98    sports       31 Aug      CricTracker   \n",
       "99    sports       31 Aug      Sportskeeda   \n",
       "\n",
       "                                                title         authors  \\\n",
       "0   India's GDP grows at 13.5% in first quarter of...    Anmol Sharma   \n",
       "1   Snap to lay off 20% of staff, cancel several p...    Anmol Sharma   \n",
       "2   2 top executives at Snap quit hours after repo...    Ananya Goyal   \n",
       "3   Musk seeks to delay Twitter trial to Nov amid ...    Ananya Goyal   \n",
       "4   Viral video shows Amazon parcels thrown out of...  Ridham Gambhir   \n",
       "..                                                ...             ...   \n",
       "95  India faced a 'lot of difficulty' when they la...    Anmol Sharma   \n",
       "96  Pant can get into this side if Rahul doesn't f...    Anmol Sharma   \n",
       "97  I can't believe his place is under threat: Sty...    Anmol Sharma   \n",
       "98  Team India can tackle our bowlers, Pak can't: ...    Anmol Sharma   \n",
       "99  Kohli will score his 71st century vs Hong Kong...   Ankur Taliyan   \n",
       "\n",
       "                                              content  \n",
       "0   India's GDP grew at 13.5% in the first quarter...  \n",
       "1   Snap said on Wednesday it will lay off 20% of ...  \n",
       "2   Two senior advertising executives at Snap quit...  \n",
       "3   Tesla CEO Elon Musk is seeking to delay the tr...  \n",
       "4   A video from Guwahati railway station has gone...  \n",
       "..                                                ...  \n",
       "95  Ex-Team India opener Wasim Jaffer said Team In...  \n",
       "96  Former India cricketer Saba Karim has said wit...  \n",
       "97  During a discussion ahead of India's match aga...  \n",
       "98  Former Afghanistan captain Asghar Afghan said ...  \n",
       "99  Sri Lanka spinner Maheesh Theekshana, during a...  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's now work on the inshort function\n",
    "# where i want to capture all required genre datasets\n",
    "\n",
    "frames = [inshort_bus, inshort_tech, inshort_ent, inshort_sports]\n",
    "\n",
    "inshort_articles = pd.concat(frames, axis = 0).reset_index(drop = True)\n",
    "inshort_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an inshort_articles\n",
    "\n",
    "inshort_articles.to_json(\"inshort_articles.json\") # checks out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "``JSON Cache Functions:``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to first: check if the Codeup Blogs dataset exists, if not: scrape the web for it\n",
    "\n",
    "def get_codeup_blogs():\n",
    "\n",
    "    # creating the operating system filename for referencing\n",
    "    filename = \"codeup_blogs.json\"\n",
    "    \n",
    "    # check to see if the file path exists\n",
    "    if os.path.isfile(filename):\n",
    "        \n",
    "        # if found, read the csv as a Pandas JSON\n",
    "        codeup_blogs = pd.read_json(filename)\n",
    "\n",
    "        # return the blogs data\n",
    "        return codeup_blogs\n",
    "    \n",
    "    # if not cached, then retrieve the data from Codeup's blog site\n",
    "    else:\n",
    "\n",
    "        # set the Codeup Blogs url\n",
    "        url = \"https://codeup.com/blog/\"\n",
    "\n",
    "        # providing url headers for referencing/web access\n",
    "        headers = {'User-Agent': 'Codeup Data Science'}\n",
    "\n",
    "        # creating the response object to access to the url\n",
    "        response = get(url, headers = headers)\n",
    "\n",
    "        # creating the Codeup Blogs soup object\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # selecting/extracting all urls from the blog home page\n",
    "        urls = soup.select('h2 a[href]')[:]\n",
    "\n",
    "        # container list to store needed contents/attributes\n",
    "        container = []\n",
    "\n",
    "        # let's extract all articles in the Codeup blog post website\n",
    "        for num in range(len(urls)):\n",
    "\n",
    "            # extracting the article url from Codeup blog urls\n",
    "            article_url = urls[num]['href']\n",
    "\n",
    "            # creating the response object (Article Website)\n",
    "            response = get(article_url, headers = headers)\n",
    "\n",
    "            # create the soup object\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "            # extract the title\n",
    "            title = soup.find('h1', class_ = \"entry-title\").text\n",
    "            \n",
    "            # extract the publish date\n",
    "            published = soup.find('span', class_ = \"published\").text.strip()\n",
    "            \n",
    "            # extract article body\n",
    "            contents = soup.find('div', class_ = 'entry-content').text.strip()\n",
    "\n",
    "            # create dictionary that holds article contents\n",
    "            article_dict = { \n",
    "                \n",
    "                \"article_title\": title,\n",
    "                \"publish_date\": published,\n",
    "                \"contents\": contents\n",
    "            }\n",
    "\n",
    "            # append article dictionary to the container list\n",
    "            container.append(article_dict)\n",
    "\n",
    "        # create an articles/blogs dataframe\n",
    "        df = pd.DataFrame(container).sort_values(\"publish_date\").reset_index(drop = True)\n",
    "        \n",
    "        # creating a .json file in local directory for future referencing\n",
    "        codeup_blogs = df.to_json(\"codeup_blogs.json\")\n",
    "\n",
    "        # return articles/blogs\n",
    "        return codeup_blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "codeup_blogs = get_codeup_blogs()\n",
    "codeup_blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
